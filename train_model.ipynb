{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as tfs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "\n",
    "import math\n",
    "from models import LogisticRegressor, Convolutional\n",
    "from run_pipeline import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 2000\n",
    "F_RANGE = (2, 40)\n",
    "W_RANGE = (-5, 0)\n",
    "W_CENTER = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = abs(F_RANGE[1] - F_RANGE[0])\n",
    "win_dim = abs(W_RANGE[1] - W_RANGE[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "<>:30: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n<>:30: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n<ipython-input-19-4e4012a1466e>:30: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n  state_condition = n_true > n_false if state is 0 else True\n"
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/mfccs_40_4096_1024.json'",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-4e4012a1466e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/mfccs_40_4096_1024.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mjson_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mn_videos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/mfccs_40_4096_1024.json'"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "n_videos = 0\n",
    "\n",
    "n_true, n_false = 0, 0\n",
    "\n",
    "def construct_tensors(matrix, state):\n",
    "    w_range = (W_RANGE[0] + W_CENTER, W_CENTER + W_RANGE[1])\n",
    "    matrix = np.abs(np.array(matrix))\n",
    "\n",
    "    # Prepare vector & matrix for regressor & convolutional\n",
    "    r_vector = matrix[W_CENTER, F_RANGE[0]:F_RANGE[1]].flatten()\n",
    "    c_matrix = matrix[w_range[0]:w_range[1], F_RANGE[0]:F_RANGE[1]]\n",
    "\n",
    "    x0 = torch.FloatTensor(r_vector)\n",
    "    x1 = torch.FloatTensor([c_matrix])\n",
    "    y = torch.tensor(state)\n",
    "    return (x0, x1, y)\n",
    "\n",
    "with open('data/mfccs_40_4096_1024.json') as f:\n",
    "    json_data = json.load(f)\n",
    "    n_videos = len(json_data)\n",
    "\n",
    "    # Loop over all videos in dataset\n",
    "    for i, video in enumerate(json_data):\n",
    "        video_data = json_data[video]\n",
    "\n",
    "        for data in video_data:\n",
    "            matrix, state = data['m'], data['s']\n",
    "            state_condition = n_true > n_false if state is 0 else True\n",
    "\n",
    "            if matrix != [] and state_condition:\n",
    "                n_true += state\n",
    "                n_false += 1 - state  \n",
    "                if i < 8:\n",
    "                    train_data.append(construct_tensors(matrix, state))\n",
    "                else:\n",
    "                    test_data.append(construct_tensors(matrix, state))\n",
    "\n",
    "print(f'Extracted {len(train_data)} train points and {len(test_data)} test points from {n_videos} videos')\n",
    "print(f'n_true: {n_true}, n_false: {n_false}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c52034305a5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(train_data[0][0].shape)\n",
    "print(train_data[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d8220f7f115c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_loader = torch.utils.data.DataLoader(dataset=train_data,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                            \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                            shuffle=True)\n\u001b[1;32m      4\u001b[0m test_loader = torch.utils.data.DataLoader(dataset=test_data,\n\u001b[1;32m      5\u001b[0m                                            \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/sam/Development/are-we-still-juggling-audio/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/sam/Development/are-we-still-juggling-audio/venv/lib/python3.8/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0m\u001b[1;32m     96\u001b[0m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Device: cuda:0\n"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "n_params=1662\nn_params=12027\n"
    }
   ],
   "source": [
    "regressor, conv = LogisticRegressor(n_features, 1, 2).to(device), Convolutional(n_features, win_dim, 2).to(device)\n",
    "print(f'n_params={sum(p.numel() for p in regressor.parameters())}')\n",
    "print(f'n_params={sum(p.numel() for p in conv.parameters())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optis = [optim.SGD(regressor.parameters(), lr=0.001), optim.SGD(conv.parameters(), lr=0.001)]\n",
    "crits = [nn.CrossEntropyLoss(), nn.CrossEntropyLoss()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, data, inds):\n",
    "    x, y = inds\n",
    "    correct, total = 0, 0\n",
    "    for xxy in data:\n",
    "        y_hat = model(xxy[x].to(device))\n",
    "        _, predicted = torch.max(y_hat.data, 1)\n",
    "        \n",
    "        total += xxy[y].size(0)\n",
    "        correct += (predicted.cpu() == xxy[y]).sum()\n",
    "\n",
    "    return 100 * int(correct) / total\n",
    "\n",
    "def confusion(model, data, inds):\n",
    "    x, y = inds\n",
    "    matrix = np.array([[0, 0], [0, 0]])\n",
    "    exampl = [[[], []], [], []]\n",
    "    for xxy in data:\n",
    "        y_hat = model(xxy[x].to(device))\n",
    "        _, predicted = torch.max(y_hat.data, 1)\n",
    "        predicted = predicted.cpu()\n",
    "\n",
    "        matrix[0, 0] += torch.sum((xxy[y] == 1) & (predicted == 1))\n",
    "        matrix[0, 1] += torch.sum((xxy[y] == 0) & (predicted == 1))\n",
    "        matrix[1, 0] += torch.sum((xxy[y] == 1) & (predicted == 0))\n",
    "        matrix[1, 1] += torch.sum((xxy[y] == 0) & (predicted == 0))\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def recall(model, data, inds):\n",
    "    x, y = inds\n",
    "    tp, fn = 0, 0\n",
    "    for xxy in data:\n",
    "        y_hat = model(xxy[x].to(device))\n",
    "        _, predicted = torch.max(y_hat.data, 1)\n",
    "\n",
    "        tp += torch.sum((xxy[y] == 1) & (predicted.cpu() == 1))\n",
    "        fn += torch.sum((xxy[y] == 1) & (predicted.cpu() == 0))\n",
    "    return int(tp) / (int(tp) + int(fn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_int = 100\n",
    "accuracy_histories = [[], []]\n",
    "n_iters = 0\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-934a06198594>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_EPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;31m# Clear gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0moptis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    for i, (x0, x1, y) in enumerate(train_loader):\n",
    "        # Clear gradients\n",
    "        optis[0].zero_grad()\n",
    "        optis[1].zero_grad()\n",
    "\n",
    "        # Make prediction and calculate loss\n",
    "        y_hat0 = regressor(x0.to(device)).cpu()\n",
    "        y_hat1 = conv(x1.to(device)).cpu()\n",
    "\n",
    "        loss0 = crits[0](y_hat0, y)\n",
    "        loss1 = crits[1](y_hat1, y)\n",
    "\n",
    "        # Calculate new gradients and optimize\n",
    "        loss0.backward()\n",
    "        loss1.backward()\n",
    "\n",
    "        optis[0].step()\n",
    "        optis[1].step()\n",
    "\n",
    "        if n_iters % log_int == 0:\n",
    "            acc0 = accuracy(regressor, train_loader, (0, 2))\n",
    "            acc1 = accuracy(regressor, test_loader, (0, 2))\n",
    "            acc2 = accuracy(conv, train_loader, (1, 2))\n",
    "            acc3 = accuracy(conv, test_loader, (1, 2))\n",
    "\n",
    "            accuracy_histories[0].append(acc1)\n",
    "            accuracy_histories[1].append(acc3)\n",
    "            \n",
    "            fepoch = 'Epoch: \\033[92m{}\\033[0m/\\033[92m{}\\033[0m'.format(epoch, N_EPOCHS)\n",
    "            fiters = 'Iter: \\033[92m{}\\033[0m'.format(n_iters)\n",
    "            facc0 = 'Acc0: \\033[92m{:.2f}%\\033[0m, \\033[92m{:.2f}%\\033[0m'.format(acc0, acc1)\n",
    "            facc1 = 'Acc1: \\033[92m{:.2f}%\\033[0m, \\033[92m{:.2f}%\\033[0m'.format(acc2, acc3)\n",
    "\n",
    "            fptime = 'Time: \\033[92m{:.0f}\\033[0ms'.format(time.time() - start)\n",
    "            print('\\r{}\\t | {}\\t | {}\\t | {}\\t | {}\\t |'.format(fepoch, fiters, facc0, facc1, fptime), end=\"\")\n",
    "        n_iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-b11bc9e96c2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'REGRESSOR CONFUSION MATRIX:\\n {confusion(regressor, test_loader, (0, 2))}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'CONVOLUTIONAL CONFUSION MATRIX:\\n {confusion(conv, test_loader, (1, 2))}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "regressor.eval()\n",
    "conv.eval()\n",
    "\n",
    "print(f'REGRESSOR CONFUSION MATRIX:\\n {confusion(regressor, test_loader, (0, 2))}')\n",
    "print(f'CONVOLUTIONAL CONFUSION MATRIX:\\n {confusion(conv, test_loader, (1, 2))}')\n",
    "\n",
    "%matplotlib inline\n",
    "x0, x1 = np.arange(len(accuracy_histories[0])) * log_int, np.arange(len(accuracy_histories[1])) * log_int\n",
    "f0, f1 = np.polyfit(x0, accuracy_histories[0], 5), np.polyfit(x1, accuracy_histories[1], 5)\n",
    "f0, f1 = np.poly1d(f0), np.poly1d(f1)\n",
    "\n",
    "plt.scatter(x0, accuracy_histories[0], color='r', alpha=0.05)\n",
    "plt.scatter(x1, accuracy_histories[1], color='b', alpha=0.05)\n",
    "plt.plot(x0, f0(x0), color='r', label='regressor')\n",
    "plt.plot(x1, f1(x1), color='b', label='convolutional')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(regressor.state_dict(), 'data/models/regressor.pkl')\n",
    "torch.save(conv.state_dict(), 'data/models/convolutional.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-16ab64c1308c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m110\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrot90\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m110\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(10):\n",
    "    print(test_data[i + 110][2])\n",
    "    plt.imshow(np.rot90(test_data[i + 110][1][0]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jogo-audio",
   "language": "python",
   "name": "jogo-audio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}