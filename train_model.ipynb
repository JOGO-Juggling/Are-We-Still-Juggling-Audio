{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "\n",
    "import math\n",
    "from models import LogisticRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10000\n",
    "N_FEATURES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Extracted 2413 datapoints (920 true and 1493 false)\n"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "n_true, n_false = 0, 0\n",
    "\n",
    "def construct_tensors(vector, state):\n",
    "    vector = vector[:N_FEATURES]\n",
    "    norm = np.linalg.norm(vector)\n",
    "    x = torch.FloatTensor(vector / norm)\n",
    "    y = torch.tensor(state)\n",
    "    return (x, y)\n",
    "\n",
    "with open('data/mfccs.json') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "    # Loop over all videos in dataset\n",
    "    for video in json_data:\n",
    "        video_data = json_data[video]\n",
    "\n",
    "        # Loop over all bounces for current video\n",
    "        for feature_vector in video_data['true']:\n",
    "            if feature_vector != []:\n",
    "                data.append(construct_tensors(feature_vector, 1))\n",
    "                n_true += 1\n",
    "\n",
    "        for feature_vector in video_data['false']:\n",
    "            if feature_vector != []:\n",
    "                data.append(construct_tensors(feature_vector, 0))\n",
    "                n_false += 1\n",
    "\n",
    "print(f'Extracted {len(data)} datapoints ({n_true} true and {n_false} false)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test (85% train)\n",
    "np.random.shuffle(data)\n",
    "split_ind = int(len(data) * 0.80)\n",
    "train_data = data[:split_ind]\n",
    "test_data = data[split_ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size=128,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                           batch_size=128,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Device: cuda:0\n"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "n_params=12\n"
    }
   ],
   "source": [
    "regressor = LogisticRegressor(N_FEATURES, 2).to(device)\n",
    "print(f'n_params={sum(p.numel() for p in regressor.parameters())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(regressor.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, data):\n",
    "    correct, total = 0, 0\n",
    "    for x, y in data:\n",
    "        y_hat = model(x.to(device))\n",
    "        _, predicted = torch.max(y_hat.data, 1)\n",
    "        \n",
    "        total += y.size(0)\n",
    "        correct += (predicted.cpu() == y).sum()\n",
    "\n",
    "    return 100 * int(correct) / total, (predicted.cpu() != y)\n",
    "\n",
    "def confusion(model, data):\n",
    "    matrix = np.array([[0, 0], [0, 0]])\n",
    "    for x, y in data:\n",
    "        y_hat = model(x.to(device))\n",
    "        _, predicted = torch.max(y_hat.data, 1)\n",
    "\n",
    "        matrix[0, 0] += torch.sum((y == 1) & (predicted.cpu() == 1))\n",
    "        matrix[0, 1] += torch.sum((y == 0) & (predicted.cpu() == 1))\n",
    "        matrix[1, 0] += torch.sum((y == 1) & (predicted.cpu() == 0))\n",
    "        matrix[1, 1] += torch.sum((y == 0) & (predicted.cpu() == 0))\n",
    "    return matrix\n",
    "\n",
    "def recall(model, data):\n",
    "    tp, fn = 0, 0\n",
    "    for x, y in data:\n",
    "        y_hat = model(x.to(device))\n",
    "        _, predicted = torch.max(y_hat.data, 1)\n",
    "\n",
    "        tp += torch.sum((y == 1) & (predicted.cpu() == 1))\n",
    "        fn += torch.sum((y == 1) & (predicted.cpu() == 0))\n",
    "    return int(tp) / (int(tp) + int(fn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch: \u001b[92m10000\u001b[0m/\u001b[92m10000\u001b[0m\t | Iter: \u001b[92m159999\u001b[0m\t | Loss: \u001b[92m0.56563604\u001b[0m, Accuracy: \u001b[92m70.39%\u001b[0m\t | Time: \u001b[92m134\u001b[0ms\t |"
    }
   ],
   "source": [
    "accuracy_history = []\n",
    "n_iters = 0\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    np.random.shuffle(data)\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make prediction and calculate loss\n",
    "        y_hat = regressor(x.to(device)).cpu()\n",
    "        loss = criterion(y_hat, y)\n",
    "\n",
    "        # Calculate new gradients and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if n_iters % 1000 == 0 or epoch == N_EPOCHS:\n",
    "            acc, _ = accuracy(regressor, test_loader)\n",
    "            \n",
    "            fepoch = 'Epoch: \\033[92m{}\\033[0m/\\033[92m{}\\033[0m'.format(epoch, N_EPOCHS)\n",
    "            fiters = 'Iter: \\033[92m{}\\033[0m'.format(n_iters)\n",
    "            floss = 'Loss: \\033[92m{:.8f}\\033[0m'.format(loss.item())\n",
    "            facc = 'Accuracy: \\033[92m{:.2f}%\\033[0m'.format(acc)\n",
    "            fptime = 'Time: \\033[92m{:.0f}\\033[0ms'.format(time.time() - start)\n",
    "\n",
    "            print('\\r{}\\t | {}\\t | {}, {}\\t | {}\\t |'.format(fepoch, fiters, floss, facc, fptime), end=\"\")\n",
    "        n_iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[103  46]\n [ 97 237]]\n"
    }
   ],
   "source": [
    "print(confusion(regressor, test_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit8096e333b6704362b4846e504197b55b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}