{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit2b7b855460ee4c0bb7a3e5dabce09b36",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "\n",
    "import math\n",
    "from models import LogisticRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():        \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Iterate through test dataset\n",
    "    for features, labels in test_loader:\n",
    "        \n",
    "        # Forward pass only to get logits/output\n",
    "        outputs = model(features)\n",
    "        \n",
    "        # Get predictions from the maximum value\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Total number of labels\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        # Total correct predictions\n",
    "        correct += (predicted == labels).sum()\n",
    "        \n",
    "    accuracy = 100 * correct // total\n",
    "    \n",
    "    # Print Loss\n",
    "    print(\"Loss: {}. Accuracy: {}\".format(loss.item(), accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(tensor([0.8789, 0.4770]), tensor(1)), (tensor([-0.2110,  0.9775]), tensor(1)), (tensor([-0.1990,  0.9800]), tensor(1)), (tensor([0.6878, 0.7259]), tensor(1)), (tensor([0.3701, 0.9290]), tensor(1)), (tensor([0.5789, 0.8154]), tensor(1)), (tensor([-0.2460,  0.9693]), tensor(1)), (tensor([-0.3732,  0.9278]), tensor(1)), (tensor([-0.9657,  0.2595]), tensor(1)), (tensor([-0.1115,  0.9938]), tensor(1))]\n"
    }
   ],
   "source": [
    "with open('data/mfccs.json') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "data = []\n",
    "for video in json_data:\n",
    "    true_count = 0\n",
    "    false_count = 0\n",
    "    for label in json_data[video]:\n",
    "        if label == 'true':\n",
    "            i_d = torch.tensor(1)\n",
    "            for lis in json_data[video][label]:\n",
    "                norm = np.linalg.norm(lis[:2])\n",
    "                new = torch.FloatTensor(np.array(lis[:2]) / norm)\n",
    "                result = (new, i_d)\n",
    "                data.append(result)\n",
    "                true_count += 1\n",
    "\n",
    "        elif label == 'false':\n",
    "            i_d = torch.tensor(0)\n",
    "            for lis in json_data[video][label]:\n",
    "                if false_count < true_count:\n",
    "                    norm = np.linalg.norm(lis[:2])\n",
    "                    new = torch.FloatTensor(np.array(lis[:2]) / norm)\n",
    "                    result = (new, i_d)\n",
    "                    data.append(result)\n",
    "                    false_count +=1\n",
    "\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = data[:1700]\n",
    "test_set = data[1700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
    "                                           batch_size=10,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
    "                                           batch_size=10,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 2\n",
    "output_dim = 2\n",
    "model = LogisticRegressor(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1000 Loss: 0.6530635952949524. Accuracy: 40\n2000 Loss: 0.723237931728363. Accuracy: 42\n3000 Loss: 0.7214637994766235. Accuracy: 42\n4000 Loss: 0.743004322052002. Accuracy: 40\n5000 Loss: 0.709425151348114. Accuracy: 44\n6000 Loss: 0.7101415991783142. Accuracy: 40\n7000 Loss: 0.6270326375961304. Accuracy: 40\n8000 Loss: 0.7114494442939758. Accuracy: 43\n9000 Loss: 0.6807051301002502. Accuracy: 53\n10000 Loss: 0.7464209794998169. Accuracy: 50\n11000 Loss: 0.7174743413925171. Accuracy: 47\n12000 Loss: 0.7063252329826355. Accuracy: 41\n13000 Loss: 0.5624274015426636. Accuracy: 49\n14000 Loss: 0.6353782415390015. Accuracy: 42\n15000 Loss: 0.59847491979599. Accuracy: 41\n16000 Loss: 0.6182931661605835. Accuracy: 42\n17000 Loss: 0.7379915714263916. Accuracy: 47\n18000 Loss: 0.6925051212310791. Accuracy: 41\n19000 Loss: 0.6243540048599243. Accuracy: 42\n20000 Loss: 0.6592890024185181. Accuracy: 43\n21000 Loss: 0.7000609636306763. Accuracy: 44\n22000 Loss: 0.6705328822135925. Accuracy: 44\n23000 Loss: 0.6703634262084961. Accuracy: 54\n24000 Loss: 0.6513118147850037. Accuracy: 43\n25000 Loss: 0.6381552219390869. Accuracy: 51\n26000 Loss: 0.680220365524292. Accuracy: 42\n27000 Loss: 0.6120457649230957. Accuracy: 42\n28000 Loss: 0.7458693981170654. Accuracy: 42\n29000 Loss: 0.6434505581855774. Accuracy: 41\n30000 Loss: 0.7115589380264282. Accuracy: 42\n31000 Loss: 0.715557336807251. Accuracy: 42\n32000 Loss: 0.6622060537338257. Accuracy: 40\n33000 Loss: 0.6524633169174194. Accuracy: 42\n34000 Loss: 0.6065793633460999. Accuracy: 49\n35000 Loss: 0.7164546847343445. Accuracy: 43\n36000 Loss: 0.6341844201087952. Accuracy: 43\n37000 Loss: 0.711262583732605. Accuracy: 42\n38000 Loss: 0.6038529276847839. Accuracy: 42\n39000 Loss: 0.7042713165283203. Accuracy: 49\n40000 Loss: 0.5984113216400146. Accuracy: 49\n41000 Loss: 0.6875203847885132. Accuracy: 47\n42000 Loss: 0.7108874917030334. Accuracy: 48\n43000 Loss: 0.663723886013031. Accuracy: 44\n44000 Loss: 0.619841456413269. Accuracy: 49\n45000 Loss: 0.7044166326522827. Accuracy: 45\n46000 Loss: 0.6129263639450073. Accuracy: 41\n47000 Loss: 0.7096503973007202. Accuracy: 45\n48000 Loss: 0.6715625524520874. Accuracy: 44\n49000 Loss: 0.6467602849006653. Accuracy: 46\n50000 Loss: 0.5983749628067017. Accuracy: 42\n51000 Loss: 0.7174140214920044. Accuracy: 44\n52000 Loss: 0.6723095774650574. Accuracy: 43\n53000 Loss: 0.7008682489395142. Accuracy: 47\n54000 Loss: 0.6047983169555664. Accuracy: 43\n55000 Loss: 0.5917307138442993. Accuracy: 41\n56000 Loss: 0.6799858212471008. Accuracy: 42\n57000 Loss: 0.5988271236419678. Accuracy: 46\n58000 Loss: 0.6877566576004028. Accuracy: 44\n59000 Loss: 0.7097722291946411. Accuracy: 47\n60000 Loss: 0.7886651754379272. Accuracy: 47\n61000 Loss: 0.7235285639762878. Accuracy: 44\n62000 Loss: 0.6274309754371643. Accuracy: 42\n63000 Loss: 0.6971259117126465. Accuracy: 44\n64000 Loss: 0.5985001921653748. Accuracy: 42\n65000 Loss: 0.6159537434577942. Accuracy: 42\n66000 Loss: 0.6246976852416992. Accuracy: 49\n67000 Loss: 0.6868846416473389. Accuracy: 42\n68000 Loss: 0.7267714738845825. Accuracy: 43\n69000 Loss: 0.658063530921936. Accuracy: 42\n70000 Loss: 0.6614710092544556. Accuracy: 44\n71000 Loss: 0.6504619717597961. Accuracy: 41\n72000 Loss: 0.6547101140022278. Accuracy: 44\n73000 Loss: 0.5637296438217163. Accuracy: 47\n74000 Loss: 0.7543922662734985. Accuracy: 49\n75000 Loss: 0.6683120727539062. Accuracy: 49\n76000 Loss: 0.7228574752807617. Accuracy: 49\n77000 Loss: 0.6988843679428101. Accuracy: 42\n78000 Loss: 0.6803776025772095. Accuracy: 45\n79000 Loss: 0.6766790151596069. Accuracy: 45\n80000 Loss: 0.6751132011413574. Accuracy: 42\n81000 Loss: 0.680034339427948. Accuracy: 42\n82000 Loss: 0.7339205741882324. Accuracy: 42\n83000 Loss: 0.8052830696105957. Accuracy: 42\n84000 Loss: 0.6402618288993835. Accuracy: 42\n85000 Loss: 0.6282669901847839. Accuracy: 42\n86000 Loss: 0.7242461442947388. Accuracy: 47\n87000 Loss: 0.6035598516464233. Accuracy: 43\n88000 Loss: 0.726996898651123. Accuracy: 49\n89000 Loss: 0.6372681856155396. Accuracy: 46\n90000 Loss: 0.6459343433380127. Accuracy: 45\n91000 Loss: 0.645129919052124. Accuracy: 45\n92000 Loss: 0.7392423748970032. Accuracy: 49\n93000 Loss: 0.7036522626876831. Accuracy: 45\n94000 Loss: 0.7135285139083862. Accuracy: 47\n95000 Loss: 0.7157856822013855. Accuracy: 42\n96000 Loss: 0.6505590677261353. Accuracy: 49\n97000 Loss: 0.6742244958877563. Accuracy: 44\n98000 Loss: 0.6437666416168213. Accuracy: 45\n99000 Loss: 0.6907986402511597. Accuracy: 41\n100000 Loss: 0.7633937001228333. Accuracy: 47\n101000 Loss: 0.7532181143760681. Accuracy: 45\n102000 Loss: 0.5857087969779968. Accuracy: 47\n103000 Loss: 0.7322223782539368. Accuracy: 43\n104000 Loss: 0.6408871412277222. Accuracy: 45\n105000 Loss: 0.714769721031189. Accuracy: 42\n106000 Loss: 0.6140618324279785. Accuracy: 44\n107000 Loss: 0.665329098701477. Accuracy: 42\n108000 Loss: 0.7269587516784668. Accuracy: 47\n109000 Loss: 0.8462377786636353. Accuracy: 42\n110000 Loss: 0.7696660161018372. Accuracy: 46\n111000 Loss: 0.7089115977287292. Accuracy: 44\n112000 Loss: 0.708584725856781. Accuracy: 41\n113000 Loss: 0.6582280993461609. Accuracy: 42\n114000 Loss: 0.6897311210632324. Accuracy: 41\n115000 Loss: 0.5908323526382446. Accuracy: 42\n116000 Loss: 0.686078667640686. Accuracy: 41\n117000 Loss: 0.6925331950187683. Accuracy: 44\n118000 Loss: 0.6012523174285889. Accuracy: 42\n119000 Loss: 0.6534219980239868. Accuracy: 45\n120000 Loss: 0.6472071409225464. Accuracy: 43\n121000 Loss: 0.6504203081130981. Accuracy: 49\n122000 Loss: 0.7540870904922485. Accuracy: 43\n123000 Loss: 0.627167820930481. Accuracy: 42\n124000 Loss: 0.6712089776992798. Accuracy: 42\n125000 Loss: 0.711431622505188. Accuracy: 50\n126000 Loss: 0.6230090856552124. Accuracy: 42\n127000 Loss: 0.6354170441627502. Accuracy: 47\n128000 Loss: 0.6350889205932617. Accuracy: 45\n129000 Loss: 0.5922651290893555. Accuracy: 45\n130000 Loss: 0.6914232969284058. Accuracy: 43\n131000 Loss: 0.5990193486213684. Accuracy: 41\n132000 Loss: 0.6321865320205688. Accuracy: 42\n133000 Loss: 0.712130069732666. Accuracy: 42\n134000 Loss: 0.6207576394081116. Accuracy: 48\n135000 Loss: 0.7510219812393188. Accuracy: 47\n136000 Loss: 0.5994890928268433. Accuracy: 42\n137000 Loss: 0.6370888948440552. Accuracy: 43\n138000 Loss: 0.8197763562202454. Accuracy: 50\n139000 Loss: 0.7260215282440186. Accuracy: 42\n140000 Loss: 0.5199514627456665. Accuracy: 43\n141000 Loss: 0.6455994844436646. Accuracy: 42\n142000 Loss: 0.7162939310073853. Accuracy: 42\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6b3e6978f4e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Forward pass to get output/logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Calculate Loss: softmax --> cross entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/selina/Ubuntu Data/Are-We-Still-Juggling-Audio/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1668\u001b[0m     \u001b[0mtens_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1670\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtens_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_overrides.py\u001b[0m in \u001b[0;36mhas_torch_function\u001b[0;34m(relevant_args)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0mimplementations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m     \"\"\"\n\u001b[0;32m--> 792\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__torch_function__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_overridable_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_overrides.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0mimplementations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m     \"\"\"\n\u001b[0;32m--> 792\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__torch_function__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_overridable_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10000\n",
    "iters = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (features, labels) in enumerate(train_loader):\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(features)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        iters += 1\n",
    "\n",
    "        if iters % 1000 == 0:\n",
    "            print(iters, end=' ')\n",
    "            evaluate()\n"
   ]
  }
 ]
}